{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a893471-75a4-4acc-b8fb-195f46000b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73c5d2c-ae2f-4e50-8104-7b55a91910b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR= 'images/train'\n",
    "TEST_DIR= 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981fcda8-c368-40a8-a43a-bc505e8511f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the images provided in the dataset we will create a data frame.\n",
    "# columns = image, label\n",
    "\n",
    "def createDataFrame(dir):\n",
    "    '''\n",
    "        directory denge train aur test ki.\n",
    "        jo bhi folder hai train(say) ke andar unko list kar dega say angry, sad, happy, etc.,\n",
    "        We will treat each folder as a label.\n",
    "        This happens in label for loop.\n",
    "\n",
    "        Next in the imagename for loop, each image in the labelled folder is traversed through.\n",
    "        That image name is added to image_paths. So image_paths stores the whole path of the image.\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    image_paths= []\n",
    "    labels=[]\n",
    "    for label in os.listdir(dir): #the dir is basically the path till images. os.listdir will find the contents of the image folder. Label will store the sub-folders present in image folder. \n",
    "        for imagename in os.listdir( os.path.join(dir,label)): #traverses each image present in the label folder. Say traverse each image present in the angry folder.\n",
    "            image_paths.append(os.path.join(dir,label,imagename)) #a path is created .../image/angry/img0013\n",
    "            labels.append(label) # in labels list, the particular label is appended. Say angry. So label stores all the emotions present.\n",
    "        print(label,\" added to DataFrame\")\n",
    "    return image_paths,labels #image_paths contain the full path, labels contain the emotion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9062b6ce-e96a-4528-828a-327c1d155961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry  added to DataFrame\n",
      "disgust  added to DataFrame\n",
      "fear  added to DataFrame\n",
      "happy  added to DataFrame\n",
      "neutral  added to DataFrame\n",
      "sad  added to DataFrame\n",
      "surprise  added to DataFrame\n"
     ]
    }
   ],
   "source": [
    "train= pd.DataFrame()\n",
    "train['image'], train['label'] = createDataFrame(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5b7fe6-6afa-4348-ba01-02907b1ab2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/train\\angry\\0.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/train\\angry\\1.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/train\\angry\\10.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/train\\angry\\10002.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/train\\angry\\10016.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28816</th>\n",
       "      <td>images/train\\surprise\\9969.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28817</th>\n",
       "      <td>images/train\\surprise\\9985.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28818</th>\n",
       "      <td>images/train\\surprise\\9990.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28819</th>\n",
       "      <td>images/train\\surprise\\9992.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28820</th>\n",
       "      <td>images/train\\surprise\\9996.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28821 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                image     label\n",
       "0            images/train\\angry\\0.jpg     angry\n",
       "1            images/train\\angry\\1.jpg     angry\n",
       "2           images/train\\angry\\10.jpg     angry\n",
       "3        images/train\\angry\\10002.jpg     angry\n",
       "4        images/train\\angry\\10016.jpg     angry\n",
       "...                               ...       ...\n",
       "28816  images/train\\surprise\\9969.jpg  surprise\n",
       "28817  images/train\\surprise\\9985.jpg  surprise\n",
       "28818  images/train\\surprise\\9990.jpg  surprise\n",
       "28819  images/train\\surprise\\9992.jpg  surprise\n",
       "28820  images/train\\surprise\\9996.jpg  surprise\n",
       "\n",
       "[28821 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train #all the training images'-paths and their respective labels are stored in the train dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670e2257-d020-4baa-8b4d-01827aee0426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry  added to DataFrame\n",
      "disgust  added to DataFrame\n",
      "fear  added to DataFrame\n",
      "happy  added to DataFrame\n",
      "neutral  added to DataFrame\n",
      "sad  added to DataFrame\n",
      "surprise  added to DataFrame\n"
     ]
    }
   ],
   "source": [
    "test= pd.DataFrame()\n",
    "test['image'], test['label'] = createDataFrame(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d85ab93-415d-4b76-9f03-a850bcf933d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/test\\angry\\10052.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/test\\angry\\10065.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/test\\angry\\10079.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/test\\angry\\10095.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/test\\angry\\10121.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>images/test\\surprise\\9806.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>images/test\\surprise\\9830.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>images/test\\surprise\\9853.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>images/test\\surprise\\9878.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>images/test\\surprise\\993.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image     label\n",
       "0       images/test\\angry\\10052.jpg     angry\n",
       "1       images/test\\angry\\10065.jpg     angry\n",
       "2       images/test\\angry\\10079.jpg     angry\n",
       "3       images/test\\angry\\10095.jpg     angry\n",
       "4       images/test\\angry\\10121.jpg     angry\n",
       "...                             ...       ...\n",
       "7061  images/test\\surprise\\9806.jpg  surprise\n",
       "7062  images/test\\surprise\\9830.jpg  surprise\n",
       "7063  images/test\\surprise\\9853.jpg  surprise\n",
       "7064  images/test\\surprise\\9878.jpg  surprise\n",
       "7065   images/test\\surprise\\993.jpg  surprise\n",
       "\n",
       "[7066 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ecba8c-ba98-4509-9180-5c7b637d649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e10289b8-e487-450a-82c8-30e55bc50ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(images): \n",
    "    '''\n",
    "    Now we will pick apart each image and perform feature extraction on them.\n",
    "    The images being received as input to the function will contain dataFrame.image column only i.e., all the paths of the images.\n",
    "    The tqdm module helps in accessing all the images that are present in the image path. \n",
    "    For loop wala image only contains the path that have been mentioned in the \n",
    "    images list. To see the progress of each image present int the path, we use tqdm module.\n",
    "    '''\n",
    "    features=[] #the features extracted through the image will be put in this list.\n",
    "    for image in tqdm(images): #will traverse every image whose path have been provided in the images.\n",
    "        img= load_img(image, grayscale=True) #converted the image to grayscale as it takes only 1 channel for processing whereas the classic RGB takes 3 channels that at times can become complex.\n",
    "        img = np.array(img) #image is converted to array\n",
    "        features.append(img) \n",
    "    features= np.array(features) #convert features to array.\n",
    "    features= features.reshape(len(features), 48,48,1) #length, image width,image height, image depth=1 as its 2D\n",
    "    return features\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd56425-410b-41dd-8b6c-7ad8c2088d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "736bc3ea-6721-4bf6-8dc6-c1846dac2f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a03710e26146128236f7233730b836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "train_features= extractFeatures(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c35e51-21e7-40ec-9a2b-0d3163b8fb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7fa34d93614c16bc697ba6849893d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features= extractFeatures(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78a8810c-d17b-45aa-aab3-d6be180b921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0 #(divided by highest pixel value = 255)\n",
    "x_test= test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97951300-b866-471e-a19b-721479f9f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make label we use labelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "447ca341-d4f3-44da-973b-d9aa20738bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le= LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60a5d1c8-0e3c-46e3-bc3e-e2844c67e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= le.transform(train['label'])\n",
    "y_test= le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f3cc908-e95f-48fd-b0fc-f7dba1b0c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= to_categorical(y_train, num_classes= 7)\n",
    "y_test= to_categorical(y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8373058d-a279-4795-87b3-e1a6fc84b671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "\n",
    "#cnn layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer, 7= number of classes\n",
    "model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f413ae09-f813-4a04-a5eb-847b40aa32d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= 'accuracy')\\\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2224f62d-7e83-4752-a8b3-4f397fe2ca5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 637ms/step - accuracy: 0.2338 - loss: 1.8407 - val_accuracy: 0.2583 - val_loss: 1.8168\n",
      "Epoch 2/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 624ms/step - accuracy: 0.2535 - loss: 1.8049 - val_accuracy: 0.2613 - val_loss: 1.7820\n",
      "Epoch 3/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 726ms/step - accuracy: 0.2709 - loss: 1.7563 - val_accuracy: 0.3394 - val_loss: 1.6289\n",
      "Epoch 4/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 733ms/step - accuracy: 0.3412 - loss: 1.6424 - val_accuracy: 0.4420 - val_loss: 1.4488\n",
      "Epoch 5/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 786ms/step - accuracy: 0.4080 - loss: 1.5127 - val_accuracy: 0.4727 - val_loss: 1.3613\n",
      "Epoch 6/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 746ms/step - accuracy: 0.4355 - loss: 1.4577 - val_accuracy: 0.4936 - val_loss: 1.3114\n",
      "Epoch 7/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7106s\u001b[0m 32s/step - accuracy: 0.4599 - loss: 1.3981 - val_accuracy: 0.5156 - val_loss: 1.2649\n",
      "Epoch 8/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 727ms/step - accuracy: 0.4804 - loss: 1.3519 - val_accuracy: 0.5180 - val_loss: 1.2652\n",
      "Epoch 9/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 727ms/step - accuracy: 0.4852 - loss: 1.3384 - val_accuracy: 0.5401 - val_loss: 1.2263\n",
      "Epoch 10/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 711ms/step - accuracy: 0.4988 - loss: 1.3088 - val_accuracy: 0.5419 - val_loss: 1.1989\n",
      "Epoch 11/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 701ms/step - accuracy: 0.5053 - loss: 1.2926 - val_accuracy: 0.5313 - val_loss: 1.2260\n",
      "Epoch 12/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 2s/step - accuracy: 0.5198 - loss: 1.2700 - val_accuracy: 0.5609 - val_loss: 1.1654\n",
      "Epoch 13/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 725ms/step - accuracy: 0.5171 - loss: 1.2576 - val_accuracy: 0.5647 - val_loss: 1.1496\n",
      "Epoch 14/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 723ms/step - accuracy: 0.5358 - loss: 1.2313 - val_accuracy: 0.5645 - val_loss: 1.1565\n",
      "Epoch 15/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 715ms/step - accuracy: 0.5334 - loss: 1.2223 - val_accuracy: 0.5676 - val_loss: 1.1460\n",
      "Epoch 16/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 724ms/step - accuracy: 0.5453 - loss: 1.2053 - val_accuracy: 0.5742 - val_loss: 1.1264\n",
      "Epoch 17/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 720ms/step - accuracy: 0.5444 - loss: 1.1925 - val_accuracy: 0.5723 - val_loss: 1.1358\n",
      "Epoch 18/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 720ms/step - accuracy: 0.5420 - loss: 1.1916 - val_accuracy: 0.5894 - val_loss: 1.1071\n",
      "Epoch 19/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 720ms/step - accuracy: 0.5508 - loss: 1.1783 - val_accuracy: 0.5845 - val_loss: 1.1076\n",
      "Epoch 20/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 722ms/step - accuracy: 0.5584 - loss: 1.1684 - val_accuracy: 0.5821 - val_loss: 1.1169\n",
      "Epoch 21/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 711ms/step - accuracy: 0.5631 - loss: 1.1491 - val_accuracy: 0.5877 - val_loss: 1.0962\n",
      "Epoch 22/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 711ms/step - accuracy: 0.5672 - loss: 1.1439 - val_accuracy: 0.5928 - val_loss: 1.0947\n",
      "Epoch 23/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7688s\u001b[0m 34s/step - accuracy: 0.5764 - loss: 1.1186 - val_accuracy: 0.5935 - val_loss: 1.0917\n",
      "Epoch 24/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 709ms/step - accuracy: 0.5683 - loss: 1.1329 - val_accuracy: 0.5805 - val_loss: 1.1074\n",
      "Epoch 25/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 709ms/step - accuracy: 0.5801 - loss: 1.1195 - val_accuracy: 0.5926 - val_loss: 1.0919\n",
      "Epoch 26/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 701ms/step - accuracy: 0.5791 - loss: 1.1098 - val_accuracy: 0.5974 - val_loss: 1.0938\n",
      "Epoch 27/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 700ms/step - accuracy: 0.5773 - loss: 1.1083 - val_accuracy: 0.5986 - val_loss: 1.0752\n",
      "Epoch 28/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 703ms/step - accuracy: 0.5901 - loss: 1.0874 - val_accuracy: 0.6015 - val_loss: 1.0651\n",
      "Epoch 29/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 712ms/step - accuracy: 0.5943 - loss: 1.0765 - val_accuracy: 0.6015 - val_loss: 1.0655\n",
      "Epoch 30/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 740ms/step - accuracy: 0.5980 - loss: 1.0677 - val_accuracy: 0.6036 - val_loss: 1.0745\n",
      "Epoch 31/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 1s/step - accuracy: 0.5946 - loss: 1.0738 - val_accuracy: 0.6029 - val_loss: 1.0631\n",
      "Epoch 32/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 1s/step - accuracy: 0.6027 - loss: 1.0555 - val_accuracy: 0.6035 - val_loss: 1.0632\n",
      "Epoch 33/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 1s/step - accuracy: 0.6013 - loss: 1.0575 - val_accuracy: 0.5992 - val_loss: 1.0739\n",
      "Epoch 34/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 1s/step - accuracy: 0.6061 - loss: 1.0478 - val_accuracy: 0.6074 - val_loss: 1.0587\n",
      "Epoch 35/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 1s/step - accuracy: 0.6039 - loss: 1.0515 - val_accuracy: 0.6060 - val_loss: 1.0576\n",
      "Epoch 36/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 1s/step - accuracy: 0.6052 - loss: 1.0411 - val_accuracy: 0.5993 - val_loss: 1.0899\n",
      "Epoch 37/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 1s/step - accuracy: 0.6107 - loss: 1.0300 - val_accuracy: 0.6042 - val_loss: 1.0575\n",
      "Epoch 38/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 1s/step - accuracy: 0.6092 - loss: 1.0359 - val_accuracy: 0.6101 - val_loss: 1.0440\n",
      "Epoch 39/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 1s/step - accuracy: 0.6166 - loss: 1.0239 - val_accuracy: 0.6107 - val_loss: 1.0493\n",
      "Epoch 40/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 1s/step - accuracy: 0.6243 - loss: 1.0063 - val_accuracy: 0.6067 - val_loss: 1.0477\n",
      "Epoch 41/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 806ms/step - accuracy: 0.6281 - loss: 1.0042 - val_accuracy: 0.6149 - val_loss: 1.0440\n",
      "Epoch 42/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 777ms/step - accuracy: 0.6205 - loss: 1.0049 - val_accuracy: 0.6112 - val_loss: 1.0464\n",
      "Epoch 43/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 776ms/step - accuracy: 0.6241 - loss: 0.9966 - val_accuracy: 0.6169 - val_loss: 1.0417\n",
      "Epoch 44/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 1s/step - accuracy: 0.6291 - loss: 0.9971 - val_accuracy: 0.6091 - val_loss: 1.0555\n",
      "Epoch 45/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 1s/step - accuracy: 0.6313 - loss: 0.9808 - val_accuracy: 0.6124 - val_loss: 1.0458\n",
      "Epoch 46/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 1s/step - accuracy: 0.6349 - loss: 0.9792 - val_accuracy: 0.6235 - val_loss: 1.0317\n",
      "Epoch 47/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 1s/step - accuracy: 0.6352 - loss: 0.9658 - val_accuracy: 0.6214 - val_loss: 1.0292\n",
      "Epoch 48/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 1s/step - accuracy: 0.6440 - loss: 0.9612 - val_accuracy: 0.6169 - val_loss: 1.0361\n",
      "Epoch 49/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 1s/step - accuracy: 0.6398 - loss: 0.9639 - val_accuracy: 0.6169 - val_loss: 1.0395\n",
      "Epoch 50/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 1s/step - accuracy: 0.6403 - loss: 0.9550 - val_accuracy: 0.6144 - val_loss: 1.0433\n",
      "Epoch 51/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 1s/step - accuracy: 0.6497 - loss: 0.9393 - val_accuracy: 0.6271 - val_loss: 1.0234\n",
      "Epoch 52/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 1s/step - accuracy: 0.6471 - loss: 0.9398 - val_accuracy: 0.6189 - val_loss: 1.0449\n",
      "Epoch 53/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 1s/step - accuracy: 0.6423 - loss: 0.9535 - val_accuracy: 0.6219 - val_loss: 1.0294\n",
      "Epoch 54/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 1s/step - accuracy: 0.6485 - loss: 0.9268 - val_accuracy: 0.6179 - val_loss: 1.0329\n",
      "Epoch 55/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 1s/step - accuracy: 0.6453 - loss: 0.9403 - val_accuracy: 0.6274 - val_loss: 1.0306\n",
      "Epoch 56/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1s/step - accuracy: 0.6528 - loss: 0.9212 - val_accuracy: 0.6200 - val_loss: 1.0314\n",
      "Epoch 57/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 1s/step - accuracy: 0.6638 - loss: 0.9190 - val_accuracy: 0.6230 - val_loss: 1.0376\n",
      "Epoch 58/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - accuracy: 0.6567 - loss: 0.9218 - val_accuracy: 0.6173 - val_loss: 1.0266\n",
      "Epoch 59/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 1s/step - accuracy: 0.6570 - loss: 0.9208 - val_accuracy: 0.6243 - val_loss: 1.0279\n",
      "Epoch 60/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 1s/step - accuracy: 0.6655 - loss: 0.9117 - val_accuracy: 0.6298 - val_loss: 1.0206\n",
      "Epoch 61/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 1s/step - accuracy: 0.6639 - loss: 0.8983 - val_accuracy: 0.6230 - val_loss: 1.0338\n",
      "Epoch 62/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 1s/step - accuracy: 0.6692 - loss: 0.8918 - val_accuracy: 0.6224 - val_loss: 1.0250\n",
      "Epoch 63/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 1s/step - accuracy: 0.6731 - loss: 0.8856 - val_accuracy: 0.6274 - val_loss: 1.0110\n",
      "Epoch 64/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 716ms/step - accuracy: 0.6746 - loss: 0.8824 - val_accuracy: 0.6210 - val_loss: 1.0203\n",
      "Epoch 65/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 713ms/step - accuracy: 0.6764 - loss: 0.8615 - val_accuracy: 0.6204 - val_loss: 1.0262\n",
      "Epoch 66/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 717ms/step - accuracy: 0.6799 - loss: 0.8693 - val_accuracy: 0.6209 - val_loss: 1.0239\n",
      "Epoch 67/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 727ms/step - accuracy: 0.6726 - loss: 0.8851 - val_accuracy: 0.6244 - val_loss: 1.0254\n",
      "Epoch 68/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 726ms/step - accuracy: 0.6767 - loss: 0.8697 - val_accuracy: 0.6279 - val_loss: 1.0213\n",
      "Epoch 69/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 717ms/step - accuracy: 0.6724 - loss: 0.8787 - val_accuracy: 0.6311 - val_loss: 1.0124\n",
      "Epoch 70/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 713ms/step - accuracy: 0.6832 - loss: 0.8585 - val_accuracy: 0.6302 - val_loss: 1.0210\n",
      "Epoch 71/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 713ms/step - accuracy: 0.6889 - loss: 0.8393 - val_accuracy: 0.6336 - val_loss: 1.0145\n",
      "Epoch 72/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 713ms/step - accuracy: 0.6896 - loss: 0.8468 - val_accuracy: 0.6223 - val_loss: 1.0310\n",
      "Epoch 73/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 711ms/step - accuracy: 0.6890 - loss: 0.8387 - val_accuracy: 0.6223 - val_loss: 1.0268\n",
      "Epoch 74/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 710ms/step - accuracy: 0.6881 - loss: 0.8478 - val_accuracy: 0.6241 - val_loss: 1.0186\n",
      "Epoch 75/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 712ms/step - accuracy: 0.6930 - loss: 0.8205 - val_accuracy: 0.6234 - val_loss: 1.0144\n",
      "Epoch 76/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 722ms/step - accuracy: 0.6840 - loss: 0.8570 - val_accuracy: 0.6326 - val_loss: 1.0180\n",
      "Epoch 77/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 718ms/step - accuracy: 0.6971 - loss: 0.8248 - val_accuracy: 0.6311 - val_loss: 1.0178\n",
      "Epoch 78/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 740ms/step - accuracy: 0.6994 - loss: 0.8176 - val_accuracy: 0.6350 - val_loss: 1.0233\n",
      "Epoch 79/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 725ms/step - accuracy: 0.6950 - loss: 0.8266 - val_accuracy: 0.6325 - val_loss: 1.0091\n",
      "Epoch 80/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 715ms/step - accuracy: 0.7017 - loss: 0.8129 - val_accuracy: 0.6306 - val_loss: 1.0219\n",
      "Epoch 81/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 716ms/step - accuracy: 0.7058 - loss: 0.7992 - val_accuracy: 0.6349 - val_loss: 1.0198\n",
      "Epoch 82/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 753ms/step - accuracy: 0.7023 - loss: 0.8064 - val_accuracy: 0.6363 - val_loss: 1.0183\n",
      "Epoch 83/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 732ms/step - accuracy: 0.7096 - loss: 0.7979 - val_accuracy: 0.6333 - val_loss: 1.0191\n",
      "Epoch 84/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 714ms/step - accuracy: 0.7075 - loss: 0.8007 - val_accuracy: 0.6316 - val_loss: 1.0216\n",
      "Epoch 85/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 713ms/step - accuracy: 0.7102 - loss: 0.7931 - val_accuracy: 0.6332 - val_loss: 1.0237\n",
      "Epoch 86/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 711ms/step - accuracy: 0.7095 - loss: 0.7937 - val_accuracy: 0.6408 - val_loss: 1.0258\n",
      "Epoch 87/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 714ms/step - accuracy: 0.7155 - loss: 0.7717 - val_accuracy: 0.6347 - val_loss: 1.0259\n",
      "Epoch 88/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 716ms/step - accuracy: 0.7115 - loss: 0.7865 - val_accuracy: 0.6285 - val_loss: 1.0325\n",
      "Epoch 89/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 713ms/step - accuracy: 0.7118 - loss: 0.7755 - val_accuracy: 0.6315 - val_loss: 1.0263\n",
      "Epoch 90/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 702ms/step - accuracy: 0.7138 - loss: 0.7804 - val_accuracy: 0.6248 - val_loss: 1.0367\n",
      "Epoch 91/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 722ms/step - accuracy: 0.7310 - loss: 0.7479 - val_accuracy: 0.6292 - val_loss: 1.0373\n",
      "Epoch 92/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 705ms/step - accuracy: 0.7219 - loss: 0.7643 - val_accuracy: 0.6281 - val_loss: 1.0311\n",
      "Epoch 93/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 707ms/step - accuracy: 0.7222 - loss: 0.7580 - val_accuracy: 0.6308 - val_loss: 1.0358\n",
      "Epoch 94/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 702ms/step - accuracy: 0.7213 - loss: 0.7524 - val_accuracy: 0.6340 - val_loss: 1.0275\n",
      "Epoch 95/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 699ms/step - accuracy: 0.7278 - loss: 0.7541 - val_accuracy: 0.6305 - val_loss: 1.0251\n",
      "Epoch 96/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 699ms/step - accuracy: 0.7233 - loss: 0.7529 - val_accuracy: 0.6228 - val_loss: 1.0393\n",
      "Epoch 97/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 704ms/step - accuracy: 0.7262 - loss: 0.7504 - val_accuracy: 0.6366 - val_loss: 1.0253\n",
      "Epoch 98/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 706ms/step - accuracy: 0.7254 - loss: 0.7538 - val_accuracy: 0.6323 - val_loss: 1.0353\n",
      "Epoch 99/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 732ms/step - accuracy: 0.7273 - loss: 0.7458 - val_accuracy: 0.6329 - val_loss: 1.0248\n",
      "Epoch 100/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 719ms/step - accuracy: 0.7334 - loss: 0.7278 - val_accuracy: 0.6245 - val_loss: 1.0468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24b00cc2170>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, validation_data= (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e879657a-f847-42ae-a799-9064c96d1976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_json= model.to_json()\n",
    "with open(\"emotiondetector.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a79aa954-82eb-4c14-9832-ecd1c69ae57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34cc45f5-6311-4110-b2c9-5e92a8cbfdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file= open(\"emotiondetector.json\",\"r\")\n",
    "model_json= json_file.read()\n",
    "json_file.close()\n",
    "model= model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a24cb821-99ae-4ee0-bbfa-1f4ccc417c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "label= ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97c585a3-3d94-4665-b827-22e83d259d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img= load_img(image,grayscale= True)\n",
    "    feature=np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7955a26a-819e-4883-a9f5-bf50dad37f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG is ANGRY\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "Model predicted :  angry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "image='images/train/angry/27.jpg'\n",
    "print(\"OG is ANGRY\")\n",
    "img= ef(image)\n",
    "pred= model.predict(img)\n",
    "pred_label= label[pred.argmax()]\n",
    "print(\"Model predicted : \", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59d0ec82-e739-49c9-a3a2-156d744b963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c69ab605-43ff-4ff8-a3f3-e16482d50d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG is ANGRY\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Model predicted :  angry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24b04122320>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image='images/train/angry/27.jpg'\n",
    "print(\"OG is ANGRY\")\n",
    "img= ef(image)\n",
    "pred= model.predict(img)\n",
    "pred_label= label[pred.argmax()]\n",
    "print(\"Model predicted : \", pred_label)\n",
    "plt.imshow(img.reshape(48,48), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044980ce-bc36-4a58-84e0-898a15593dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
